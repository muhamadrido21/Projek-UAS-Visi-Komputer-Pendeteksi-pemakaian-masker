{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### 1. Motivation<br>\nCovid-19 started in November 2019 and started to spread across the world killing 3.74 million people. To curb the spread were to wear masks and maintain 6 feet distance. Although vaccines are available now and the cases have come down in some few countries, many countries are still struggling. In order to aid in stopping the spread and identify individuals not following the safety policies, we aim to build an Object Detection and Convolution Neural Network based face mask and social distance detection system. The dataset to be used contains numerous images of instances where people are with and without mask and the model aims to identify people violating safety policies and flag the images with violation concerns. <br>\n","metadata":{}},{"cell_type":"markdown","source":"**Objective:**\n\nIdentiying if a person is wearing facemask or not and violating any social distance norms.","metadata":{}},{"cell_type":"code","source":"## Importing libraries\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport glob\nfrom scipy.spatial import distance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, models\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:26:56.843336Z","iopub.execute_input":"2021-10-12T07:26:56.843736Z","iopub.status.idle":"2021-10-12T07:27:03.126608Z","shell.execute_reply.started":"2021-10-12T07:26:56.843642Z","shell.execute_reply":"2021-10-12T07:27:03.125402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting the directories, Path and Data","metadata":{}},{"cell_type":"code","source":"path = \"../input/face-mask-12k-images-dataset/Face Mask Dataset/\"","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:03.128066Z","iopub.execute_input":"2021-10-12T07:27:03.128371Z","iopub.status.idle":"2021-10-12T07:27:03.133711Z","shell.execute_reply.started":"2021-10-12T07:27:03.12834Z","shell.execute_reply":"2021-10-12T07:27:03.13131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = {\n    \"image_path\": [],\n    \"mask_status\": [],\n    \"where\": []\n}\n\nfor where in os.listdir(path):\n    for status in os.listdir(path+\"/\"+where):\n        for image in glob.glob(path+where+\"/\"+status+\"/\"+\"*.png\"):\n            dataset[\"image_path\"].append(image)\n            dataset[\"mask_status\"].append(status)\n            dataset[\"where\"].append(where)\n            \ndataset = pd.DataFrame(dataset)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:03.135551Z","iopub.execute_input":"2021-10-12T07:27:03.135827Z","iopub.status.idle":"2021-10-12T07:27:03.523346Z","shell.execute_reply.started":"2021-10-12T07:27:03.1358Z","shell.execute_reply":"2021-10-12T07:27:03.522407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Face Detection using HAAR Cascade Algorithm","metadata":{}},{"cell_type":"code","source":"## Choosing a random image to detect the face in the image\nface_model = cv2.CascadeClassifier('../input/haarcascades/haarcascade_frontalface_default.xml')\n\n## Choosing the image from the directory\nimg = cv2.imread(\"../input/face-mask-detection/images/maksssksksss352.png\")\n\n## Converting the image to grayscale to apply haarcascade algorithm\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\n## Returns the x, y, w, h co-ordinates as numpy arrays for all the detected faces\ndetected_face = face_model.detectMultiScale(img)\n\n## Converting from grayscale to colored image\noutput_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n## Drawing rectangle box around the faces in the image\nfor (x, y, w, h) in detected_face:\n    cv2.rectangle(output_img, (x,y), (x+w, y+h), (0, 0, 200), 2)\n    \n## Displaying the image\nplt.figure(figsize = (15, 15))\nplt.imshow(output_img)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:03.524767Z","iopub.execute_input":"2021-10-12T07:27:03.525046Z","iopub.status.idle":"2021-10-12T07:27:04.413965Z","shell.execute_reply.started":"2021-10-12T07:27:03.525016Z","shell.execute_reply":"2021-10-12T07:27:04.413182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Drawbacks:","metadata":{}},{"cell_type":"markdown","source":"We can observe that Default face detection Haar Cascading that we choose doesnt do a good job in identifying the faces. (Will replace this with other algorithms)","metadata":{}},{"cell_type":"markdown","source":"### Detecting Social Distance","metadata":{}},{"cell_type":"code","source":"if len(detected_face) >= 2:\n    # Track to check for violation of social distance violation\n    label = [0 for i in range(len(detected_face))]\n    \n    # Getting the distance from one image to rest of the image  \n    for i in range(len(detected_face)-1):\n        for j in range(i+1, len(detected_face)):\n            # [:2] gets only x, y co ordinates\n            dist = distance.euclidean(detected_face[i][:2], detected_face[j][:2])\n            # Checking if the distance is less than 6 feet \n            if dist < 130:\n                # If less than 6 feet, flag the respective images\n                label[i] = 1\n                label[j] = 1\n    \n    # Coloring the image\n    new_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    \n    # Coloring the rectangle around the image\n    for i in range(len(detected_face)):\n        (x, y, w, h) = detected_face[i]\n        if label[i] == 1:\n            # If its 1, then the distance is less than 6 feet so mark red\n            cv2.rectangle(new_image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n        else:\n            # If not mark green \n            cv2.rectangle(new_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n         \n    plt.figure(figsize = (10, 10))\n    plt.imshow(new_image)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:04.415436Z","iopub.execute_input":"2021-10-12T07:27:04.415908Z","iopub.status.idle":"2021-10-12T07:27:04.717446Z","shell.execute_reply.started":"2021-10-12T07:27:04.415875Z","shell.execute_reply":"2021-10-12T07:27:04.716393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: Red showing that they are not 6 feet apart. Green shows that they are 6 feet apart","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualisations","metadata":{}},{"cell_type":"code","source":"## Checking for total number of images in the dataset\nprint(f\"With Mask:\", dataset.value_counts(\"mask_status\")[0])\nprint(f\"Without Mask:\", dataset.value_counts(\"mask_status\")[1])\n\n## Plotting the numbers\nsns.countplot(x = dataset[\"mask_status\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:04.718998Z","iopub.execute_input":"2021-10-12T07:27:04.71943Z","iopub.status.idle":"2021-10-12T07:27:04.849624Z","shell.execute_reply.started":"2021-10-12T07:27:04.719384Z","shell.execute_reply":"2021-10-12T07:27:04.848772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15, 10))\n\nfor i in range(9):\n    random = np.random.randint(1, len(dataset))\n    plt.subplot(3, 3, i+1)\n    plt.imshow(cv2.imread(dataset.loc[random,\"image_path\"]))\n    plt.title(dataset.loc[random,\"mask_status\"], size = 15)\n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:04.850966Z","iopub.execute_input":"2021-10-12T07:27:04.851255Z","iopub.status.idle":"2021-10-12T07:27:05.50929Z","shell.execute_reply.started":"2021-10-12T07:27:04.851226Z","shell.execute_reply":"2021-10-12T07:27:05.508201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Splitting train test and Validation Dataset\ntrain_df = dataset[dataset[\"where\"] == \"Train\"]\ntest_df = dataset[dataset[\"where\"] == \"Test\"]\nvalid_df = dataset[dataset[\"where\"] == \"Validation\"]\n\nprint(train_df.head(10))\n\n## Shuffling the dataset \ntrain_df = train_df.sample(frac = 1)\ntest_df = test_df.sample(frac = 1)\nvalid_df = valid_df.sample(frac = 1)\n\nprint(\"\\n After Shuffling \\n\")\nprint(train_df.head(10))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:05.51149Z","iopub.execute_input":"2021-10-12T07:27:05.511811Z","iopub.status.idle":"2021-10-12T07:27:05.534201Z","shell.execute_reply.started":"2021-10-12T07:27:05.511779Z","shell.execute_reply":"2021-10-12T07:27:05.533006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualising the distribution of train test and validation set","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\nplt.subplot(1, 3, 1)\nsns.countplot(x = train_df[\"mask_status\"])\nplt.title(\"Training Dataset\", size = 10)\n\nplt.subplot(1, 3, 2)\nsns.countplot(x = test_df[\"mask_status\"])\nplt.title(\"Test Dataset\", size = 10)\n\nplt.subplot(1, 3, 3)\nsns.countplot(x = valid_df[\"mask_status\"])\nplt.title(\"Validation Dataset\", size = 10)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:05.535949Z","iopub.execute_input":"2021-10-12T07:27:05.536309Z","iopub.status.idle":"2021-10-12T07:27:05.834265Z","shell.execute_reply.started":"2021-10-12T07:27:05.536276Z","shell.execute_reply":"2021-10-12T07:27:05.833297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index().drop(\"index\", axis = 1)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:05.835485Z","iopub.execute_input":"2021-10-12T07:27:05.835774Z","iopub.status.idle":"2021-10-12T07:27:05.84951Z","shell.execute_reply.started":"2021-10-12T07:27:05.835742Z","shell.execute_reply":"2021-10-12T07:27:05.848414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Reading all the image into a list and changing the size of the image to (150,150)\ndata = []\nimage_size = 150\n\nfor i in range(len(train_df)):\n    ## Converting the image into grayscale\n    img_array = cv2.imread(train_df[\"image_path\"][i], cv2.IMREAD_GRAYSCALE)\n\n    ## Resizing the array\n    new_image_array = cv2.resize(img_array, (image_size, image_size))\n\n    ##Encoding the image with the label\n    if train_df[\"mask_status\"][i] == \"WithMask\":\n        data.append([new_image_array, 1])\n    else:\n        data.append([new_image_array, 0])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:27:05.852865Z","iopub.execute_input":"2021-10-12T07:27:05.853251Z","iopub.status.idle":"2021-10-12T07:28:24.394138Z","shell.execute_reply.started":"2021-10-12T07:27:05.853213Z","shell.execute_reply":"2021-10-12T07:28:24.393155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.39544Z","iopub.execute_input":"2021-10-12T07:28:24.395839Z","iopub.status.idle":"2021-10-12T07:28:24.411879Z","shell.execute_reply.started":"2021-10-12T07:28:24.395794Z","shell.execute_reply":"2021-10-12T07:28:24.410838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.413209Z","iopub.execute_input":"2021-10-12T07:28:24.413492Z","iopub.status.idle":"2021-10-12T07:28:24.41959Z","shell.execute_reply.started":"2021-10-12T07:28:24.413463Z","shell.execute_reply":"2021-10-12T07:28:24.418602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Shuffling the data to make sure everything is not in order\nnp.random.shuffle(data)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.420897Z","iopub.execute_input":"2021-10-12T07:28:24.421199Z","iopub.status.idle":"2021-10-12T07:28:24.441473Z","shell.execute_reply.started":"2021-10-12T07:28:24.421167Z","shell.execute_reply":"2021-10-12T07:28:24.440417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Looking at the training samples\n\nfig, ax = plt.subplots(2, 3, figsize=(10, 10))\n\nfor row in range(2):\n    for col in range(3):\n        image_index = row*100+col\n        \n        ax[row, col].axis(\"off\")\n        ax[row,col].imshow(data[image_index][0], cmap = \"gray\")\n    \n        if data[image_index][1] == 0:\n            ax[row, col].set_title(\"Without Mask\")\n        else:\n            ax[row, col].set_title(\"With Mask\")\n            \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.443028Z","iopub.execute_input":"2021-10-12T07:28:24.443385Z","iopub.status.idle":"2021-10-12T07:28:24.823303Z","shell.execute_reply.started":"2021-10-12T07:28:24.443351Z","shell.execute_reply":"2021-10-12T07:28:24.822263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datagen = ImageDataGenerator(rescale = 1./255)\n\n# train_generator=datagen.flow_from_dataframe(\n# dataframe=train_df,\n# directory=\"../input\",\n# x_col=\"image_path\",\n# y_col=\"mask_status\",\n# batch_size=80,\n# seed=42,\n# shuffle=False,\n# class_mode=\"binary\",\n# target_size=(150,150))","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.824612Z","iopub.execute_input":"2021-10-12T07:28:24.824905Z","iopub.status.idle":"2021-10-12T07:28:24.828037Z","shell.execute_reply.started":"2021-10-12T07:28:24.824872Z","shell.execute_reply":"2021-10-12T07:28:24.827346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing data to be loaded into the Model","metadata":{}},{"cell_type":"code","source":"X = []\ny = []\n\n## Seperating X and y\nfor image in data:\n    X.append(image[0])\n    y.append(image[1])\n    \n## Converting X and y to numpy array as Tensorflow accepts only numpy arrays\nX = np.array(X)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:24.82913Z","iopub.execute_input":"2021-10-12T07:28:24.829446Z","iopub.status.idle":"2021-10-12T07:28:25.0037Z","shell.execute_reply.started":"2021-10-12T07:28:24.829417Z","shell.execute_reply":"2021-10-12T07:28:25.002613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Normalizing the data\nX = X/255\n\n### Train Test Split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:25.005237Z","iopub.execute_input":"2021-10-12T07:28:25.005543Z","iopub.status.idle":"2021-10-12T07:28:27.286456Z","shell.execute_reply.started":"2021-10-12T07:28:25.005507Z","shell.execute_reply":"2021-10-12T07:28:27.285316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, (3, 3), activation = \"relu\"))\nmodel.add(Conv2D(64, (3, 3), activation = \"relu\"))\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = \"relu\"))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:27.287623Z","iopub.execute_input":"2021-10-12T07:28:27.287905Z","iopub.status.idle":"2021-10-12T07:28:27.333602Z","shell.execute_reply.started":"2021-10-12T07:28:27.287877Z","shell.execute_reply":"2021-10-12T07:28:27.332509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:27.334856Z","iopub.execute_input":"2021-10-12T07:28:27.335162Z","iopub.status.idle":"2021-10-12T07:28:27.356118Z","shell.execute_reply.started":"2021-10-12T07:28:27.33513Z","shell.execute_reply":"2021-10-12T07:28:27.35517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = X_train.reshape(-1, 32, 150, 150)\n## Reshaping training set to match Conc2D\nX_train = X_train.reshape(len(X_train), X_train.shape[1], X_train.shape[2], 1)\nX_val = X_val.reshape(len(X_val), X_val.shape[1], X_val.shape[2], 1)\n\nhistory = model.fit(X_train, y_train, epochs=5, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2021-10-12T07:28:27.357521Z","iopub.execute_input":"2021-10-12T07:28:27.357828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict_classes(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_val, prediction))\nprint(confusion_matrix(y_val, prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}